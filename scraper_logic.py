from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
from bs4 import BeautifulSoup
from bleach import clean
import time


def wait_for_full_description(driver, selector, min_length=500, timeout=15):
    end_time = time.time() + timeout
    while time.time() < end_time:
        try:
            elem = driver.find_element(By.CSS_SELECTOR, selector)
            if len(elem.text.strip()) >= min_length:
                return True
        except Exception:
            pass
        time.sleep(0.5)
    return False

def extract_job_details(driver, url):
    driver.get(url)
    print(f"\n Visiting: {url}")

    try:
        title = WebDriverWait(driver, 60).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "h1.font-heading-3"))
        ).text.strip()
    except TimeoutException:
        title = "[Not Found]"

    try:
        location = driver.find_element(By.CSS_SELECTOR, "span.loc").text.strip()
    except Exception:
        location = "[Not Found]"

    
    try:
        try:
            company_elem = driver.find_element(By.CSS_SELECTOR, "a.companyInfo")
        except:
            company_elem = driver.find_element(By.CSS_SELECTOR, "span.companyInfo")
        company = company_elem.text.strip()
    except Exception:
        company = "[Not Found]"

   
    if wait_for_full_description(driver, "div.inner-content", min_length=500):
        soup = BeautifulSoup(driver.page_source, "html.parser")
        desc_container = soup.select_one("div.inner-content")
        with open("job_debug_raw.html", "w", encoding="utf-8") as f:
            f.write(desc_container.prettify() if desc_container else "")
        raw_html = desc_container.decode_contents() if desc_container else "[Not Found]"
    else:
        raw_html = "[Not Found or Incomplete]"

    allowed_tags = ['p', 'br', 'ul', 'li', 'ol', 'strong', 'em', 'h2', 'h3', 'a', 'b']
    allowed_attrs = {'a': ['href', 'title']}
    if "<span" in raw_html:
        raw_html = raw_html.replace("<span>", "").replace("</span>", "")
    description = clean(raw_html, tags=allowed_tags, attributes=allowed_attrs)

    print("======== JOB DEBUG INFO ========")
    print("üîó URL:", url)
    print("\nüî§ RAW HTML EXCERPT:\n", raw_html[:1000])
    print("\nüßº CLEANED HTML EXCERPT:\n", description[:1000])
    print("=================================\n")

    print("===== JOB DETAIL EXTRACTED =====")
    print("Title:", title)
    print("Location:", location)
    print("Link:", url)
    print("\nDescription Preview:\n", description[:400], "\n")

    return {
        "title": title,
        "company": company,
        "location": location,
        "link": url,
        "description": description
    }


def scrape_jobs(title, location, max_jobs=10, seniority=None, region="US"):
    print("üîç BASIC DEBUG: Function called with parameters:")
    print(f"  - title: '{title}'")
    print(f"  - location: '{location}'") 
    print(f"  - max_jobs: {max_jobs}")
    print(f"  - seniority: '{seniority}'")
    
    try:
        print("üåê Launching browser...")
        options = Options()
    
        # === CONVERT TO HEADLESS WITH ANTI-DETECTION ===
        options.add_argument("--headless")  # Changed from --start-maximized
        options.add_argument("--no-sandbox") 
        options.add_argument("--disable-dev-shm-usage")
        options.add_argument("--disable-gpu")
        options.add_argument("--window-size=1920,1080")
    
        # === ADD PROVEN ANTI-DETECTION ===
        user_agent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/137.0.0.0 Safari/537.36"
        options.add_argument(f"--user-agent={user_agent}")
        options.add_argument("--disable-blink-features=AutomationControlled")
        options.add_experimental_option("excludeSwitches", ["enable-automation"])
        options.add_experimental_option('useAutomationExtension', False)
        options.add_argument("--disable-web-security")
        options.add_argument("--allow-running-insecure-content")
    
        driver = webdriver.Chrome(options=options)
    
        # === ADD ANTI-DETECTION SCRIPT ===
        driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")

        # === REST OF YOUR EXACT WORKING LOGIC ===
        if region == "US":
            base_url = "https://www.efinancialcareers.com/"
        elif region == "UK":
            base_url = "https://www.efinancialcareers.co.uk/"
        elif region == "SG":
            base_url = "https://www.efinancialcareers.sg/"
        elif region == "DE":
            base_url = "https://www.efinancialcareers.de/"
        else:
            base_url = "https://www.efinancialcareers.com/"  # Default to US
        print(f"üåç REGION DEBUG: Using region '{region}' -> URL: {base_url}")
        print(f"üåê ACTUAL URL BEING ACCESSED: About to navigate to {base_url}")
    
        driver.get(base_url)
        time.sleep(2)
        print(f"üåê CURRENT URL AFTER NAVIGATION: {driver.current_url}")
        print(f"üåê PAGE TITLE: {driver.title}")
        print(f"üåê PAGE LANGUAGE: Checking for German content...")

        # Check if page has German elements
        try:
            german_elements = driver.find_elements(By.XPATH, "//*[contains(text(), 'Suche') or contains(text(), 'Stellenangebote') or contains(text(), 'Berufserfahrung')]")
            print(f"üåê GERMAN ELEMENTS FOUND: {len(german_elements)}")
            if german_elements:
                print(f"üåê SAMPLE GERMAN TEXT: {german_elements[0].text}")
        except:
            print(f"üåê NO GERMAN ELEMENTS DETECTED")

        print("‚å®Ô∏è Filling job title and location...")
        WebDriverWait(driver, 60).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "input[placeholder='Job title, keyword or company']"))
        ).send_keys(title)

        WebDriverWait(driver, 60).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "input[placeholder='Location']"))
        ).send_keys(location)

        # Try German search button first, then English
        try:
            search_button = driver.find_element(By.XPATH, "//button[contains(text(), 'Suche')]")
            print("üá©üá™ Found German 'Suche' button")
        except:
            try:
                search_button = driver.find_element(By.CSS_SELECTOR, "button[type='submit']")
                print("üá∫üá∏ Found English submit button")
            except:
                search_button = driver.find_element(By.XPATH, "//button[contains(@class, 'search') or contains(@class, 'submit')]")
                print("üîç Found generic search button")

        search_button.click()
        
        time.sleep(5)

        # DEBUG: Check what we actually got after the search
        print("üîç DEBUG: Checking search results after initial search...")
        try:
            # Look for the job count indicator
            result_text = driver.find_element(By.XPATH, "//*[contains(text(), 'job in')]").text
            print(f"üìä Results found on page: {result_text}")
    
            # Count actual job cards
            initial_cards = driver.find_elements(By.CSS_SELECTOR, "a.font-subtitle-3-medium.job-title")
            print(f"üìã Job cards found: {len(initial_cards)}")
    
            # Check if "No more jobs!" exists immediately
            no_more_msg = driver.find_elements(By.XPATH, "//*[contains(text(), 'No more jobs!')]")
            print(f"üîö 'No more jobs!' message present: {len(no_more_msg) > 0}")
    
        except Exception as e:
            print(f"‚ö†Ô∏è DEBUG: Could not get initial search info: {e}")
    
        print(f"üîç SENIORITY RECEIVED: '{seniority}' (type: {type(seniority)})")

        # Handle seniority filtering if specified
        if seniority:
            print(f"üéØ Applying seniority filter: {seniority}")
            try:
                print("‚è≥ Waiting for search results page to load...")
                WebDriverWait(driver, 65).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, "a.font-subtitle-3-medium.job-title"))
                )
                time.sleep(3)
        
                print("üîΩ Opening seniority filter...")
                filter_buttons = driver.find_elements(By.CSS_SELECTOR, "efc-filter-button")
                seniority_btn = None
                for btn in filter_buttons:
                    if "Seniority" in btn.text:
                        seniority_btn = btn.find_element(By.TAG_NAME, "button")
                        break
        
                if seniority_btn:
                    seniority_btn.click()
                    time.sleep(2)

                    seniority_mapping = {
                        'intern': 'INTERN_GRADUATE',
                        'junior': 'JUNIOR', 
                        'analyst': 'ANALYST',
                        'associate': 'ASSOCIATE_MID_LEVEL',
                        'avp': 'AVP_SENIOR',
                        'vp': 'VP_PRINCIPAL',
                        'svp': 'SVP_HEAD_OF',
                        'director': 'DIRECTOR',
                        'md': 'MANAGING_DIRECTOR',
                        'csuite': 'C_SUITE'
                    }


                    checkbox_value = seniority_mapping.get(seniority)
                    if checkbox_value:
                        print(f"‚òëÔ∏è Looking for checkbox with value: {checkbox_value}")
    
                        # Try to find the specific seniority checkbox
                        try:
                            checkbox = driver.find_element(By.ID, f"seniority{checkbox_value}")
                            print(f"‚úÖ Seniority option '{seniority}' found in dropdown")
                        except:
                            print(f"üö´ Seniority level '{seniority}' not available for this search")
                            driver.quit()
                            return [{"no_results": True, "special_message": f"No {seniority} level positions available for '{title}' in {location}. Try a different seniority level."}]
                    
                        if not checkbox.is_selected():
                            checkbox.click()
                            time.sleep(2)
                            print(f"‚úÖ Clicked checkbox for {checkbox_value}")
            
                            print("‚è≥ Waiting for filtered results to reload...")
                            WebDriverWait(driver, 65).until(
                                EC.presence_of_element_located((By.CSS_SELECTOR, "a.font-subtitle-3-medium.job-title"))
                            )
                            time.sleep(3)
                else:
                    raise Exception("Seniority button not found")
                
                print("‚úÖ Seniority filter applied successfully")

                # DEBUG: Wait and check if job count updates    
                print("üîç DEBUG: Checking job count after filter...")
                time.sleep(5)
                try:
                    result_text = driver.find_element(By.XPATH, "//*[contains(text(), 'job in')]").text
                    print(f"üìä Updated job count: {result_text}")
                except:
                    print("üìä Could not find job count text")
            
                # DEBUG: Check what jobs are visible immediately after filtering
                print("üîç DEBUG: Checking jobs immediately after seniority filter...")
                immediate_cards = driver.find_elements(By.CSS_SELECTOR, "a.font-subtitle-3-medium.job-title")
                print(f"Jobs found immediately: {len(immediate_cards)}")
                for i, card in enumerate(immediate_cards):
                    try:
                        title = card.text.strip()
                        print(f"  Immediate Job {i+1}: '{title}'")
                    except:
                        print(f"  Immediate Job {i+1}: Could not read title")
         
            
                # DEBUG: Save the actual page we're on after filtering
                print("üîç DEBUG: Saving filtered page source...")
                with open("filtered_results_debug.html", "w", encoding="utf-8") as f:
                    f.write(driver.page_source)

                # DEBUG: Check current URL
                print(f"üåê Current URL after filtering: {driver.current_url}")

                # DEBUG: Look for the specific job count text
                try:
                    job_count_elements = driver.find_elements(By.XPATH, "//*[contains(text(), 'Operational Risk job in New York')]")
                    for elem in job_count_elements:
                        stored_job_count_text = elem.text
                        print(f"üìä Found job count text: '{elem.text}'")
                except Exception as e:
                    print(f"‚ö†Ô∏è Could not find job count text: {e}")

      
            except Exception as e:
                print(f"‚ö†Ô∏è Could not apply seniority filter: {e}")

        job_links = []
    
        # Get the expected number of jobs from the page indicator
        try:
            job_count_text = stored_job_count_text if 'stored_job_count_text' in locals() else ""
            # Extract number from text like "Operational Risk job in New York (1)"
            import re
            count_match = re.search(r'\((\d+)\)', job_count_text)
            if count_match:
                expected_jobs = int(count_match.group(1))
                print(f"üéØ Successfully extracted job count: {expected_jobs}")
            else:
                expected_jobs = 999
                print(f"‚ùå Regex failed to extract number from: '{job_count_text}'")
        except:
            expected_jobs = 999  # Fallback if we can't find the count
            print("‚ö†Ô∏è Could not find job count, collecting all")

        # Collect only the expected number of jobs
        cards = driver.find_elements(By.CSS_SELECTOR, "efc-job-search-results efc-job-card a.font-subtitle-3-medium.job-title")
        print(f"üîç Total cards found: {len(cards)}")

        for i, card in enumerate(cards):
            if i >= expected_jobs:  # Stop when we reach the expected count
                print(f"üõë Reached expected job count ({expected_jobs}), stopping collection")
                break
        
            try:
                href = card.get_attribute("href")
                if href:
                    job_links.append(href)
                    print(f"‚úÖ Collected job {i+1}: '{card.text.strip()}'")
            except Exception:
                continue

        print(f"üîç Found {len(job_links)} job links.\n")
    

        # ‚úÖ Collect only valid jobs until we reach max_jobs
        job_results = []
        for url in job_links:
            job = extract_job_details(driver, url)

            if (
                job["title"] == "[Not Found]" or
                job["location"] == "[Not Found]" or
                job["description"] == "[Not Found or Incomplete]"
            ):
                print("‚õî Skipping invalid job.")
                continue

            job_results.append(job)
            print(f"‚úÖ Collected: {len(job_results)} / {max_jobs}")
            time.sleep(2)

            if len(job_results) >= max_jobs:
                break
    
        driver.quit()
        return job_results
        
    except TimeoutException as e:
        print(f"‚ùå TIMEOUT ERROR: {e}")
        if 'driver' in locals():
            driver.quit()
        return [{
            "error_type": "timeout",
            "title": "Search Timeout",
            "company": "Error",
            "location": location,
            "link": "#",
            "description": "The job site is taking longer than usual to respond. Please try again with fewer results (5-10 jobs) or try a different location. If this keeps happening, email us at frameitbot@gmail.com",
            "formatted_description": "The job site is taking longer than usual to respond. Please try again with fewer results (5-10 jobs) or try a different location. If this keeps happening, email us at frameitbot@gmail.com"
        }]
        
    except Exception as e:
        print(f"‚ùå GENERAL ERROR: {e}")
        if 'driver' in locals():
            driver.quit()
        error_msg = "We're experiencing technical difficulties. Please try again in a few minutes. If you continue seeing this error, email frameitbot@gmail.com with details about what you were searching for."
        
        return [{
            "error_type": "general",
            "title": "Technical Error",
            "company": "Error", 
            "location": location,
            "link": "#",
            "description": error_msg,
            "formatted_description": error_msg
        }]


